{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os \n",
    "import json\n",
    "from torchmetrics import F1Score,JaccardIndex, Accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "from torchmetrics.classification import BinaryStatScores\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Import TuSimple loader\n",
    "import sys\n",
    "sys.path.insert(0,'../resources/')\n",
    "from tusimple import TuSimple\n",
    "import utils\n",
    "from vit import ViT\n",
    "from mlp_decoder import DecoderMLP\n",
    "\n",
    "\n",
    "\n",
    "# ROOT DIRECTORIES\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "annotated_dir = os.path.join(root_dir,'datasets/tusimple/train_set/annotations')\n",
    "clips_dir = os.path.join(root_dir,'datasets/tusimple/train_set/')\n",
    "annotated_dir_test = os.path.join(root_dir,'datasets/tusimple/test_set/annotations/')\n",
    "test_clips_dir = os.path.join(root_dir,'datasets/tusimple/test_set/')\n",
    "\n",
    "\n",
    "annotated = os.listdir(annotated_dir)\n",
    "\n",
    "\n",
    "test_annotated = os.listdir(annotated_dir_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path directories for clips and annotations for the TUSimple training  dataset + ground truth dictionary\n",
    "# annotations = list()\n",
    "# for gt_file in annotated:\n",
    "#     path = os.path.join(annotated_dir,gt_file)\n",
    "#     json_gt = [json.loads(line) for line in open(path)]\n",
    "#     annotations.append(json_gt)\n",
    "    \n",
    "# annotations = [a for f in annotations for a in f]\n",
    "\n",
    "\n",
    "# Get path directories for clips and annotations for the TUSimple test dataset + ground truth dictionary\n",
    "test_annotations = list()\n",
    "for gt_file in test_annotated:\n",
    "    path = os.path.join(annotated_dir_test,gt_file)\n",
    "    json_gt = [json.loads(line) for line in open(path)]\n",
    "    test_annotations.append(json_gt)\n",
    "    \n",
    "test_annotations = [a for f in test_annotations for a in f]\n",
    "\n",
    "test_dataset = TuSimple(train_annotations = test_annotations, train_img_dir = test_clips_dir, resize_to = (448,448), subset_size = 0.001, test = True, previous= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from : https://github.com/vinceecws/SegNet_PyTorch/blob/master/Pavements/SegNet.py\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_chn=3, out_chn=1, BN_momentum=0.5):\n",
    "        super(SegNet, self).__init__()\n",
    "        \n",
    "        #SegNet Architecture\n",
    "        #Takes input of size in_chn = 3 (RGB images have 3 channels)\n",
    "        #Outputs size label_chn (N # of classes)\n",
    "\n",
    "        self.lane_threshold = 0.5\n",
    "        self.in_chn = in_chn\n",
    "        self.out_chn = out_chn\n",
    "\n",
    "        self.MaxEn = nn.MaxPool2d(2, stride=2, return_indices=True) \n",
    "\n",
    "        self.ConvEn11 = nn.Conv2d(self.in_chn, 64, kernel_size=3, padding=1)\n",
    "        self.BNEn11 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "        self.ConvEn12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.BNEn12 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvEn21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.BNEn21 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "        self.ConvEn22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.BNEn22 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvEn31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.BNEn31 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvEn32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.BNEn32 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvEn33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.BNEn33 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvEn41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn41 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvEn51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNEn53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "\n",
    "        #DECODING consists of 5 stages\n",
    "        #Each stage corresponds to their respective counterparts in ENCODING\n",
    "\n",
    "        #General Max Pool 2D/Upsampling for DECODING layers\n",
    "        self.MaxDe = nn.MaxUnpool2d(2, stride=2) \n",
    "\n",
    "        self.ConvDe53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNDe53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNDe52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNDe51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNDe43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.BNDe42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe41 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.BNDe41 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.BNDe33 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvDe32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.BNDe32 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvDe31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.BNDe31 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.BNDe22 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "        self.ConvDe21 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.BNDe21 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.BNDe12 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "        self.ConvDe11 = nn.Conv2d(64, self.out_chn, kernel_size=3, padding=1)\n",
    "        self.BNDe11 = nn.BatchNorm2d(self.out_chn, momentum=BN_momentum)\n",
    "        \n",
    "\n",
    "    # Count pipeline trainable parameters\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.local_response_norm(x, size=3)\n",
    "\n",
    "        #ENCODE LAYERS\n",
    "        #Stage 1\n",
    "        x = F.relu(self.BNEn11(self.ConvEn11(x))) \n",
    "        x = F.relu(self.BNEn12(self.ConvEn12(x)))\n",
    "         \n",
    "        x, ind1 = self.MaxEn(x)\n",
    "        size1 = x.size()\n",
    "\n",
    "\n",
    "        #Stage 2\n",
    "        x = F.relu(self.BNEn21(self.ConvEn21(x))) \n",
    "        x = F.relu(self.BNEn22(self.ConvEn22(x))) \n",
    "        \n",
    "        x, ind2 = self.MaxEn(x)\n",
    "        size2 = x.size()\n",
    "\n",
    "        #Stage 3\n",
    "        x = F.relu(self.BNEn31(self.ConvEn31(x))) \n",
    "        x = F.relu(self.BNEn32(self.ConvEn32(x))) \n",
    "        x = F.relu(self.BNEn33(self.ConvEn33(x)))\n",
    "        \n",
    "        x, ind3 = self.MaxEn(x)\n",
    "        size3 = x.size()\n",
    "        \n",
    "        #Stage 4\n",
    "        x = F.relu(self.BNEn41(self.ConvEn41(x))) \n",
    "        x = F.relu(self.BNEn42(self.ConvEn42(x))) \n",
    "        x = F.relu(self.BNEn43(self.ConvEn43(x)))   \n",
    "         \n",
    "        x, ind4 = self.MaxEn(x)\n",
    "        size4 = x.size()\n",
    "\n",
    "        #Stage 5\n",
    "        x = F.relu(self.BNEn51(self.ConvEn51(x))) \n",
    "        x = F.relu(self.BNEn52(self.ConvEn52(x))) \n",
    "        x = F.relu(self.BNEn53(self.ConvEn53(x)))\n",
    "            \n",
    "        x, ind5 = self.MaxEn(x)\n",
    "        size5 = x.size()\n",
    "\n",
    "        #DECODE LAYERS\n",
    "        #Stage 5\n",
    "        x = self.MaxDe(x, ind5, output_size=size4)\n",
    "        x = F.relu(self.BNDe53(self.ConvDe53(x)))\n",
    "        x = F.relu(self.BNDe52(self.ConvDe52(x)))\n",
    "        x = F.relu(self.BNDe51(self.ConvDe51(x)))\n",
    "\n",
    "        #Stage 4\n",
    "        x = self.MaxDe(x, ind4, output_size=size3)\n",
    "        x = F.relu(self.BNDe43(self.ConvDe43(x)))\n",
    "        x = F.relu(self.BNDe42(self.ConvDe42(x)))\n",
    "        x = F.relu(self.BNDe41(self.ConvDe41(x)))\n",
    "\n",
    "        #Stage 3\n",
    "        x = self.MaxDe(x, ind3, output_size=size2)\n",
    "        x = F.relu(self.BNDe33(self.ConvDe33(x)))\n",
    "        x = F.relu(self.BNDe32(self.ConvDe32(x)))\n",
    "        x = F.relu(self.BNDe31(self.ConvDe31(x)))\n",
    "\n",
    "        #Stage 2\n",
    "        x = self.MaxDe(x, ind2, output_size=size1)\n",
    "        x = F.relu(self.BNDe22(self.ConvDe22(x)))\n",
    "        x = F.relu(self.BNDe21(self.ConvDe21(x)))\n",
    "\n",
    "        #Stage 1\n",
    "        x = self.MaxDe(x, ind1)\n",
    "        x = F.relu(self.BNDe12(self.ConvDe12(x)))\n",
    "        x = self.ConvDe11(x)\n",
    "        \n",
    "        probs = F.sigmoid(x)\n",
    "        \n",
    "        return x,probs\n",
    "\n",
    "    # Make a single prediction \n",
    "    def predict(self,x):\n",
    "        self.eval()\n",
    "        cnn_features,probs = self.forward(x)\n",
    "        prediction = torch.where(probs > self.lane_threshold, torch.ones_like(probs), torch.zeros_like(probs))\n",
    "        return prediction,cnn_features\n",
    "    \n",
    "    # Predict with temporal post-processing\n",
    "    def predict_temporal (self,x):\n",
    "        self.eval()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        with torch.no_grad():\n",
    "            for clip in x:\n",
    "                base_frame = clip.to(device)\n",
    "                # Predict mask probs for base frame\n",
    "                _,base_mask_prob = self.forward(base_frame.unsqueeze(0))\n",
    "            \n",
    "                previous_masks = []\n",
    "            \n",
    "                # Predict masks probs for previous frames\n",
    "                for i in range(1,len(x)):\n",
    "                    prev_frame = x[i].to(device)\n",
    "                    _,prev_mask = self.forward(prev_frame.unsqueeze(0))\n",
    "                    previous_masks.append(prev_mask)\n",
    "                \n",
    "                # Define the decay factor for the previous frames weights\n",
    "                decay_factor = 0.8\n",
    "\n",
    "                # Calculate the weights for each previous frame\n",
    "                weights = [decay_factor**i for i in range(len(clip[0])- 1)]\n",
    "            \n",
    "                # Normalize the weights so that they sum to 1\n",
    "                weights /= np.sum(weights)\n",
    "\n",
    "                # Loop over the previous frames and update the class probabilities for the target frame\n",
    "                for i, prev_mask in enumerate(previous_masks):\n",
    "                    weight = weights[i]\n",
    "                    update_mask = (base_mask_prob < 0.85)\n",
    "                    base_mask_prob[update_mask] = (1 - weight) * base_mask_prob[update_mask] + weight * prev_mask[update_mask]\n",
    "                # # Loop over the previous frames and update the class probabilities for the target frame\n",
    "                # for i, prev_mask in enumerate(previous_masks):\n",
    "                #     weight = weights[i]\n",
    "                #     base_mask_prob[:, 0, :, :] = (1 - weight) * base_mask_prob[:, 0, :, :] + weight * prev_mask[:, 0, :, :]\n",
    "                \n",
    "            prediction = torch.where(base_mask_prob > self.lane_threshold, torch.ones_like(base_mask_prob), torch.zeros_like(base_mask_prob))\n",
    "            \n",
    "        return prediction\n",
    "            \n",
    "    # Load trained model weights\n",
    "    def load_weights(self,path): \n",
    "        self.load_state_dict(torch.load(path,map_location=torch.device('cpu')))\n",
    "        print('Loaded state dict succesfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset / Calculate pos weight\n",
    "dataset = TuSimple(train_annotations = annotations, train_img_dir = clips_dir, resize_to = (448,448), subset_size = 0.001,val_size= 0.1)\n",
    "train_set, validation_set = dataset.train_val_split()\n",
    "del dataset\n",
    "\n",
    "# Lane weight\n",
    "pos_weight = utils.calculate_class_weight(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set function (with temporal post-processing)\n",
    "def evaluate(model, test_set):\n",
    "    # Set up device (GPU or CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    f1_score = F1Score(task=\"binary\").to(device)\n",
    "    iou_score = JaccardIndex(task= 'binary').to(device)\n",
    "    stat_scores = BinaryStatScores().to(device)\n",
    "    accuracy = Accuracy(task=\"binary\").to(device)\n",
    "        \n",
    "    test_f1 = 0\n",
    "    test_iou = 0\n",
    "    test_accuracy = 0\n",
    "    fps_temp = 0\n",
    "    \n",
    "    \n",
    "    no_temp_f1 = 0\n",
    "    no_temp_iou = 0\n",
    "    no_temp_accuracy = 0\n",
    "    fps_no = 0\n",
    "    \n",
    "    all_stats_no = []\n",
    "    all_stats_temp = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for clip in test_set:\n",
    "            gt = clip[1].to(device)\n",
    "            base_frame = clip[0][0].to(device)\n",
    "            \n",
    "            start_time1 = time.time()\n",
    "            \n",
    "            start_time2 = time.time()\n",
    "            \n",
    "            # Predict mask probs for base frame\n",
    "            _,base_mask_prob = model.forward(base_frame.unsqueeze(0))\n",
    "            \n",
    "            end_time1 = time.time()\n",
    "            \n",
    "            # Get F1 scores,IoU and Accuracy before temporal post process\n",
    "            no_temp_f1 += f1_score(base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            no_temp_iou += iou_score(base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            no_temp_accuracy += accuracy(base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            \n",
    "            # Measure FPS without temporal post process\n",
    "            processing_time = end_time1 - start_time1\n",
    "            fps_no += (1 / processing_time)\n",
    "            \n",
    "            # Get stats to calculate FPR/FNR\n",
    "            all_stats_no.append(stat_scores(base_mask_prob.to(device), gt.unsqueeze(0)))\n",
    "            \n",
    "            previous_masks = []\n",
    "            \n",
    "            # Predict masks probs for previous frames\n",
    "            for i in range(1,len(clip[0])):\n",
    "                prev_frame = clip[0][i].to(device)\n",
    "                _,prev_mask = model.forward(prev_frame.unsqueeze(0))\n",
    "                previous_masks.append(prev_mask)\n",
    "            \n",
    "            # Define the decay factor for the previous frames weights\n",
    "            decay_factor = 0.8\n",
    "\n",
    "            # Calculate the weights for each previous frame\n",
    "            weights = [decay_factor**i for i in range(len(clip[0])- 1)]\n",
    "            \n",
    "            # Normalize the weights so that they sum to 1\n",
    "            weights /= np.sum(weights)\n",
    "            \n",
    "            \n",
    "            # Loop over the previous frames and update the class probabilities for the target frame\n",
    "            for i, prev_mask in enumerate(previous_masks):\n",
    "                weight = weights[i]\n",
    "                base_mask_prob[:, 0, :, :] = (1 - weight) * base_mask_prob[:, 0, :, :] + weight * prev_mask[:, 0, :, :]\n",
    "                \n",
    "            end_time2 = time.time()\n",
    "            \n",
    "            # Measure FPS with temporal post process\n",
    "            processing_time = end_time2 - start_time2\n",
    "            fps_temp += (1 / processing_time)\n",
    "            \n",
    "            # Compare new mask with temporal post process with gt and get evaluation scores\n",
    "            test_f1 += f1_score(base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            test_iou += iou_score (base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            test_accuracy += accuracy(base_mask_prob.to(device), gt.unsqueeze(0))\n",
    "            \n",
    "            # Get stats for FNR/FPR with temporal\n",
    "            all_stats_temp.append(stat_scores(base_mask_prob.to(device), gt.unsqueeze(0)))\n",
    "            \n",
    "        # Get FPR and FNR for test set (with and without temporal)\n",
    "        \n",
    "        fp1_sum = torch.stack([s[1] for s in all_stats_no]).sum()\n",
    "        fn1_sum = torch.stack([s[3] for s in all_stats_no]).sum()\n",
    "        tn1_sum = torch.stack([s[2] for s in all_stats_no]).sum()\n",
    "        tp1_sum = torch.stack([s[0] for s in all_stats_no]).sum()\n",
    "        \n",
    "        # Average fpr without temporal\n",
    "        fpr_no = fp1_sum / (tn1_sum + fp1_sum)\n",
    "        fnr_no = fn1_sum / (tp1_sum + fn1_sum)\n",
    "        \n",
    "        fp2_sum = torch.stack([s[1] for s in all_stats_temp]).sum()\n",
    "        fn2_sum = torch.stack([s[3] for s in all_stats_temp]).sum()\n",
    "        tn2_sum = torch.stack([s[2] for s in all_stats_temp]).sum()\n",
    "        tp2_sum = torch.stack([s[0] for s in all_stats_temp]).sum()\n",
    "        \n",
    "        # Average fpr and fnr with temporal\n",
    "        fpr_temp = fp2_sum / (tn2_sum + fp2_sum)\n",
    "        fnr_temp = fn2_sum / (tp2_sum + fn2_sum)\n",
    "        \n",
    "        # Calculate test set average metrics\n",
    "        test_f1 /= len(test_set)\n",
    "        test_iou /= len(test_set)\n",
    "        no_temp_f1 /= len(test_set)\n",
    "        no_temp_iou /= len(test_set)\n",
    "        no_temp_accuracy /= len(test_set)\n",
    "        test_accuracy /= len(test_set)\n",
    "        fps_temp /= len(test_set)\n",
    "        fps_no /= len(test_set)\n",
    "        \n",
    "        # Create lists of metrics with and without temporal post process\n",
    "        \n",
    "        without = [round(fpr_no.item(),4), round(fnr_no.item(),4), round(no_temp_f1.item(),3), round(no_temp_iou.item(),3), round(no_temp_accuracy.item(),3) * 100, round(float(fps_no),3)]\n",
    "        \n",
    "        temporal = [round(fpr_temp.item(),4), round(fnr_temp.item(),4), round(test_f1.item(),3), round(test_iou.item(),3),round(test_accuracy.item(),3) * 100 ,round(float(fps_temp),3)]\n",
    "        \n",
    "        return without,temporal\n",
    "            \n",
    "\n",
    "# Plot metrics function \n",
    "def plot_metrics(train_losses, val_losses, train_f1, val_f1, train_iou, val_iou):\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation')\n",
    "    plt.xlabel('Epochs (bins of 5)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(range(0, len(train_losses) + 1, 5))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation F1 scores\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_f1) + 1), train_f1, label='Train')\n",
    "    plt.plot(range(1, len(val_f1) + 1), val_f1, label='Validation')\n",
    "    plt.xlabel('Epochs (bins of 5)')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xticks(range(0, len(train_f1) + 1, 5))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation IoU scores\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_iou) + 1), train_iou, label='Train')\n",
    "    plt.plot(range(1, len(val_iou) + 1), val_iou, label='Validation')\n",
    "    plt.xlabel('Epochs (bins of 5)')\n",
    "    plt.ylabel('IoU Score')\n",
    "    plt.xticks(range(0, len(train_iou) + 1, 5))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Custom training function for the pipeline with schedule and augmentations\n",
    "def train(model, train_loader, val_loader = None, num_epochs=10, lr=0.01, weight_decay=0, SGD_momentum = 0.9, lr_scheduler=False, lane_weight = None):\n",
    "    # Set up loss function and optimizer\n",
    "    criterion =  nn.BCEWithLogitsLoss(pos_weight= lane_weight)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=SGD_momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # Set up learning rate scheduler\n",
    "    if lr_scheduler:\n",
    "        pass\n",
    "\n",
    "    # Set up device (GPU or CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    f1_score = F1Score(task=\"binary\").to(device)\n",
    "    iou_score = JaccardIndex(task= 'binary').to(device)\n",
    "    \n",
    "    gt_augmentations = transforms.Compose([transforms.RandomRotation(degrees=(10, 30)),\n",
    "                                              transforms.RandomHorizontalFlip()])\n",
    "  \n",
    "    train_augmentations = transforms.Compose([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "                                            transforms.ColorJitter(brightness=0.35, contrast=0.2, saturation=0.4, hue=0.1)])\n",
    "    # Set a seed for augmentations\n",
    "    torch.manual_seed(42) \n",
    "    \n",
    "    # Metrics collection for plotting\n",
    "    train_losses = []\n",
    "    train_f1_scores = []\n",
    "    train_iou_scores = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_f1_scores = []\n",
    "    val_iou_scores = []\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_iou = 0\n",
    "        train_f1 = 0\n",
    "        \n",
    "        val_iou = 0\n",
    "        val_f1 = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            # Combine the inputs and targets into a single tensor\n",
    "            data = torch.cat((inputs, targets), dim=1)\n",
    "            # Apply the same augmentations to the combined tensor\n",
    "            augmented_data = gt_augmentations(data)    \n",
    "    \n",
    "            # Split the augmented data back into individual inputs and targets\n",
    "            inputs = augmented_data[:, :inputs.size(1)]\n",
    "            targets = augmented_data[:, inputs.size(1):].to(device)\n",
    "\n",
    "            inputs = train_augmentations(inputs).to(device)\n",
    "      \n",
    "            optimizer.zero_grad()\n",
    "            outputs, eval_out = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs.to(device), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_iou += iou_score(eval_out.to(device).detach(), targets)\n",
    "            train_f1 += f1_score(eval_out.to(device).detach(),targets)\n",
    "        \n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(val_loader): \n",
    "                \n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    logits,outputs = model(inputs)\n",
    "                    \n",
    "                    \n",
    "                    val_loss = criterion(logits.to(device),targets)\n",
    "                    val_loss += val_loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    val_iou += iou_score(outputs.to(device), targets)\n",
    "                    val_f1 += f1_score(outputs.to(device),targets)\n",
    "\n",
    "                val_loss /= len(val_loader)\n",
    "                val_iou /= len(val_loader)\n",
    "                val_f1 /= len(val_loader)\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        train_iou /= len(train_loader)\n",
    "        train_f1 /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Collect metrics for plotting\n",
    "        train_losses.append(train_loss)\n",
    "        train_f1_scores.append(train_f1)\n",
    "        train_iou_scores.append(train_iou)\n",
    "    \n",
    "        if val_loader:\n",
    "            val_losses.append(val_loss)\n",
    "            val_f1_scores.append(val_f1)\n",
    "            val_iou_scores.append(val_iou)\n",
    "        \n",
    "        \n",
    "     # Print progress\n",
    "        if lr_scheduler:\n",
    "            print('Epoch: {} - Train Loss: {:.4f} - Learning Rate: {:.6f} - Train_IoU: {:.5f} - Train_F1: {:.5f}'.format(epoch+1, train_loss,optimizer.param_groups[0]['lr'], train_iou, train_f1))\n",
    "            # scheduler.step()\n",
    "            if val_loader:\n",
    "                print('Val_F1: {:.5f}  - Val_IoU: {:.5f} '.format(val_f1,val_iou))\n",
    "        else:\n",
    "            print('Epoch: {} - Train Loss: {:.4f} - Train_IoU: {:.5f} - Train_F1: {:.5f}'.format(epoch+1, train_loss, train_iou, train_f1))\n",
    "            \n",
    "            if val_loader:\n",
    "                print('Val_Loss: {} - Val_F1: {:.5f}  - Val_IoU: {:.5f} '.format(val_loss,val_f1,val_iou))\n",
    "    \n",
    "    if val_loader:\n",
    "        return train_losses,train_f1_scores,train_iou_scores,val_losses,val_f1_scores,val_iou_scores\n",
    "    else:\n",
    "        return train_losses,train_f1_scores,train_iou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters : 29443587\n",
      "Loaded state dict succesfully!\n"
     ]
    }
   ],
   "source": [
    "model = SegNet()\n",
    "print(f'Number of trainable parameters : {model.count_parameters()}')\n",
    "model.load_weights('../models/best_segnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted marked frames dir\n",
    "pred_frames_dir = '../clips/pred_frames'\n",
    "output_file = '../clips/pred_vid_good_temp.mp4'\n",
    "make_video(pred_frames_dir, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitris/anaconda3/envs/py10/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "without, temporal = evaluate(model,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for train and validation \n",
    "train_loader = DataLoader(train_set, batch_size= 2,shuffle= True, drop_last= True, num_workers= 4) \n",
    "validation_loader = DataLoader(validation_set,batch_size= 2, shuffle= True, drop_last= True, num_workers= 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_losses,train_f1_scores,train_iou_scores,val_losses,val_f1_scores,val_iou_scores = train(model, train_loader,val_loader= validation_loader , num_epochs= 2, \n",
    "                                                                                        lane_weight = pos_weight, lr = 0.01, SGD_momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics after training for train and validation sets (bins of 5 epochs)\n",
    "plot_metrics(train_losses,val_losses,train_f1_scores,val_f1_scores,train_iou_scores,val_iou_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f74cedf3fe8df28562f21d2c7dd20a528944420e9979c6ce3cb4240ded655862"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
