{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dimitris/Downloads/Lane-detection-Master-Thesis/datasets/tusimple/train_set/annotations\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.transforms import ToPILImage\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "# Set seed for randomize functions (Ez reproduction of results)\n",
    "random.seed(100)\n",
    "\n",
    "\n",
    "# ROOT DIRECTORIES\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "annotated_dir = os.path.join(root_dir,'datasets/tusimple/train_set/annotations')\n",
    "clips_dir = os.path.join(root_dir,'datasets/tusimple/train_set/')\n",
    "annotated = os.listdir(annotated_dir)\n",
    "\n",
    "print(annotated_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path directories for clips and annotations for the TUSimple dataset + ground truth dictionary\n",
    "annotations = list()\n",
    "for gt_file in annotated:\n",
    "    path = os.path.join(annotated_dir,gt_file)\n",
    "    json_gt = [json.loads(line) for line in open(path)]\n",
    "    annotations.append(json_gt)\n",
    "    \n",
    "annotations = [a for f in annotations for a in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TuSimple Dataset loader and pre-processing class\n",
    "# Full Size: Train(3626 clips/ 20 frames per clip/ 20th only is annotated), Test(2782 clips/ 20 frames per clip/ 20th only annotated)\n",
    "# Link: https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection\n",
    "class TuSimple(Dataset):  \n",
    "    def __init__(self, train_annotations : list, train_img_dir: str, resize_to : tuple , subset_size = 0.2, image_size = (1280,720), val_size = 0.15):\n",
    "        self.images_size = image_size\n",
    "        self.resize = resize_to\n",
    "        self.val_size = val_size\n",
    "        self.subset = subset_size\n",
    "        self.train_dir = train_img_dir\n",
    "        self.complete_gt = train_annotations\n",
    "        self.complete_size = len(train_annotations)\n",
    "        self.train_dataset, self.train_gt = self.generate_dataset()\n",
    "        \n",
    "    def __len__(self):\n",
    "        if len(self.train_dataset) == len(self.train_gt):\n",
    "            return len(self.train_gt)\n",
    "        else:\n",
    "            return \"Dataset generation failure: Size of training images does not match the existing ground truths.\"\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.train_dataset) == len(self.train_gt):\n",
    "            img_tensor = self.train_dataset[idx]\n",
    "            img_gt = self.train_gt[idx]\n",
    "            return img_tensor, img_gt\n",
    "        else:\n",
    "            return \"The dataset hasn't been constructed properly. Generate again!\"\n",
    "    \n",
    "    # Generate segmentation mask for a given image NOTE: np.array image dims = (H,W,C)\n",
    "    def generate_seg_mask(self,ground_truth: dict):\n",
    "        image_path = ground_truth['raw_file']\n",
    "        image = cv2.imread(os.path.join(self.train_dir,image_path))\n",
    "        \n",
    "        masks = np.zeros_like(image[:,:,0])\n",
    "        nolane_token = -2 \n",
    "        h_vals = ground_truth['h_samples']\n",
    "        lanes = ground_truth['lanes']\n",
    "        lane_val = 255\n",
    "        \n",
    "        lane_markings_list = []\n",
    "        for lane in lanes:\n",
    "            x_coords = []\n",
    "            y_coords = []\n",
    "            for i in range(0,len(lane)):             \n",
    "                if lane[i] != nolane_token:\n",
    "                    x_coords.append(lane[i])\n",
    "                    y_coords.append(h_vals[i])\n",
    "                    lane_markings = list(zip(x_coords, y_coords))\n",
    "            lane_markings_list.append(lane_markings)        \n",
    "        for z in lane_markings_list:\n",
    "            for x,y in z:\n",
    "                masks[y,x] = 1\n",
    "        seg_mask = cv2.bitwise_and(image, image, mask=masks)\n",
    "        seg_mask [seg_mask != 0] = lane_val\n",
    "        return seg_mask  \n",
    "\n",
    "\n",
    "    # Returns original image size for the dataset    \n",
    "    def get_original_size(self):\n",
    "        return self.images_size\n",
    "    \n",
    "    # Helper func to display image with OpenCV\n",
    "    def disp_img(self, image: np.array , name = 'Image'):\n",
    "        cv2.imshow(name,image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    # Helper func to transform back to array from tensor\n",
    "    def toImagearr(self,img_tens):\n",
    "        convert = transforms.Compose([transforms.ToPILImage()])\n",
    "        im_array = np.array(convert(img_tens))\n",
    "        return im_array\n",
    "    \n",
    "    # Helper func to plot image and ground truth simultaneously\n",
    "    def plot_img_gt(self, tensor, gt_mask):\n",
    "        img = self.toImagearr(tensor) \n",
    "        Hori = np.concatenate((img, gt_mask), axis=1)\n",
    "        self.disp_img(Hori,'Image/Ground Truth')\n",
    "               \n",
    "    # Get list of lists containing ground truth lane pixel values for all lanes with respect to the original number of lanes in the original gt\n",
    "    def get_resized_gt(self, original_gt: dict, new_size = tuple):\n",
    "        seg_gt_mask = self.generate_seg_mask(original_gt)\n",
    "        resized_gt_mask = cv2.resize(seg_gt_mask, new_size, interpolation = cv2.INTER_LINEAR)\n",
    "                \n",
    "        # Set all resized pixels color to white (thresholding)\n",
    "        resized_gt_mask [resized_gt_mask !=0] = 255\n",
    "        \n",
    "        gt_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Resize(size = self.resize)])\n",
    "        \n",
    "        resized_gt_tensor = gt_transforms(seg_gt_mask)\n",
    "        \n",
    "        new_gt = {'ground_truth_mask': resized_gt_mask,'gt_tensor': resized_gt_tensor,'raw_file': original_gt['raw_file']}\n",
    "        \n",
    "        return new_gt\n",
    "              \n",
    "    # Partition dataset according to input subset size and dynamically generate the train/val splits\n",
    "    def generate_dataset(self):\n",
    "        train_set = []\n",
    "        \n",
    "        complete_idx = [idx for idx in range(0, self.complete_size + 1)]\n",
    "        target_samples = int(self.complete_size * self.subset)\n",
    "        # val_samples = int(len(target_samples) * self.val_size)\n",
    "        shuffled = random.sample(complete_idx,len(complete_idx))\n",
    "        \n",
    "        # Pick n (target samples no) idx from the shuffled dataset\n",
    "        dataset_idxs = [shuffled[idx] for idx in range(0, target_samples)]\n",
    "        train_gt = [self.complete_gt[idx] for idx in dataset_idxs]\n",
    "        \n",
    "        resized_train_gt = [self.get_resized_gt(ground,self.resize) for ground in train_gt]\n",
    "        \n",
    "        # Load images, resize inputs, generate resized ground truth seg masks,transform to tensors and generate dataset (or subset)\n",
    "        for gt in train_gt:\n",
    "            img_path = gt['raw_file']\n",
    "            train_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                                   transforms.Resize(size = self.resize)])\n",
    "            image = cv2.imread(os.path.join(self.train_dir, img_path))\n",
    "            \n",
    "            img_tensor = train_transforms(image)\n",
    "            train_set.append(img_tensor)\n",
    "        \n",
    "        return train_set, resized_train_gt   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TuSimple(train_annotations = annotations, train_img_dir = clips_dir, resize_to = (640,640), subset_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tns, gt = dataset[0]\n",
    "dataset.plot_img_gt(img_tns,gt['ground_truth_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
