{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dimitris/Downloads/Lane-detection-Master-Thesis/datasets/tusimple/train_set/annotations\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "\n",
    "# Set seed for randomize functions (Ez reproduction of results)\n",
    "random.seed(100)\n",
    "\n",
    "\n",
    "# ROOT DIRECTORIES\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "annotated_dir = os.path.join(root_dir,'datasets/tusimple/train_set/annotations')\n",
    "clips_dir = os.path.join(root_dir,'datasets/tusimple/train_set/')\n",
    "annotated = os.listdir(annotated_dir)\n",
    "\n",
    "print(annotated_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path directories for clips and annotations for the TUSimple dataset + ground truth dictionary\n",
    "annotations = list()\n",
    "for gt_file in annotated:\n",
    "    path = os.path.join(annotated_dir,gt_file)\n",
    "    json_gt = [json.loads(line) for line in open(path)]\n",
    "    annotations.append(json_gt)\n",
    "    \n",
    "annotations = [a for f in annotations for a in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for our data splits\n",
    "class BaseSplitClass(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TuSimple Dataset loader and pre-processing class\n",
    "# Full Size: Train(3626 clips/ 20 frames per clip/ 20th only is annotated), Test(2782 clips/ 20 frames per clip/ 20th only annotated)\n",
    "# Link: https://github.com/TuSimple/tusimple-benchmark/tree/master/doc/lane_detection\n",
    "class TuSimple(Dataset):  \n",
    "    def __init__(self, train_annotations : list, train_img_dir: str, resize_to : tuple , subset_size = 0.2, image_size = (1280,720), val_size = 0):\n",
    "        self.images_size = image_size\n",
    "        self.resize = resize_to\n",
    "        self.subset = subset_size\n",
    "        self.train_dir = train_img_dir\n",
    "        self.complete_gt = train_annotations\n",
    "        self.complete_size = len(train_annotations)\n",
    "        self.sf_w = round(resize_to[1] / 1280, 4)\n",
    "        self.sf_h = round(resize_to[0] / 720, 4)\n",
    "        self.val_size = val_size\n",
    "        self.train_dataset, self.train_gt = self.generate_dataset()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.train_dataset) == len(self.train_gt):\n",
    "            return len(self.train_gt)\n",
    "        else:\n",
    "            return \"Dataset generation failure: Size of training images does not match the existing ground truths.\"\n",
    "    \n",
    "    # return element from the trainset\n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.train_dataset) == len(self.train_gt):\n",
    "            img_tensor = self.train_dataset[idx]\n",
    "            img_gt = self.train_gt[idx]\n",
    "            return img_tensor, img_gt\n",
    "        else:\n",
    "            return \"The dataset hasn't been constructed properly. Generate again!\"\n",
    "    \n",
    "    # Generate segmentation mask for a given image NOTE: np.array image dims = (H,W,C)\n",
    "    def generate_seg_mask(self,ground_truth: dict):\n",
    "        image_path = ground_truth['raw_file']\n",
    "        image = cv2.imread(os.path.join(self.train_dir,image_path))\n",
    "        \n",
    "        nolane_token = -2 \n",
    "        h_vals = ground_truth['h_samples']\n",
    "        lanes = ground_truth['lanes']\n",
    "        lane_val = 255\n",
    "        \n",
    "        lane_markings_list = []\n",
    "        for lane in lanes:\n",
    "            x_coords = []\n",
    "            y_coords = []\n",
    "            for i in range(0,len(lane)):             \n",
    "                if lane[i] != nolane_token:\n",
    "                    x_coords.append(lane[i])\n",
    "                    y_coords.append(h_vals[i])\n",
    "                    lane_markings = list(zip(x_coords, y_coords))\n",
    "            lane_markings_list.append(lane_markings)  \n",
    "        \n",
    "        # Find resized lane anchor points\n",
    "        resized_lanes = []\n",
    "    \n",
    "        for lane in lane_markings_list:\n",
    "            resized_lane = []\n",
    "            for c in lane:\n",
    "                new_c = (int(c[0] * self.sf_w), int(c[1] * self.sf_h))\n",
    "                resized_lane.append(new_c)\n",
    "            resized_lanes.append(resized_lane)\n",
    "        \n",
    "        # Create empty black mask for ground truth\n",
    "        resized_mask = np.zeros(self.resize,dtype= np.uint8)\n",
    "        \n",
    "        # loop through the lane points and draw thickened white polylines for each lane\n",
    "        for lane_points_resized in resized_lanes:\n",
    "            cv2.polylines(resized_mask, [np.array(lane_points_resized)], isClosed=False, color=(255, 255, 255), thickness=5)\n",
    "              \n",
    "        return resized_mask  \n",
    "\n",
    "\n",
    "    # Returns original image size for the dataset    \n",
    "    def get_original_size(self):\n",
    "        return self.images_size\n",
    "    \n",
    "    # Helper func to display image with OpenCV\n",
    "    def disp_img(self, image: np.array , name = 'Image'):\n",
    "        cv2.imshow(name,image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    # Helper func to transform back to array from tensor\n",
    "    def toImagearr(self,img_tens):\n",
    "        convert = transforms.Compose([transforms.ToPILImage()])\n",
    "        im_array = np.array(convert(img_tens))\n",
    "        return im_array\n",
    "    \n",
    "    # Helper func to plot image and ground truth simultaneously\n",
    "    def plot_img_gt(self, tensor, gt_mask):\n",
    "        img = self.toImagearr(tensor) \n",
    "        rgb_tensor = torch.stack((gt_mask,)*3, dim=1).squeeze(0)\n",
    "        gt_mask = self.toImagearr(rgb_tensor)\n",
    "        Hori = np.concatenate((img, gt_mask), axis=1)\n",
    "        self.disp_img(Hori,'Image/Ground Truth')\n",
    "               \n",
    "    # Get list of lists containing ground truth lane pixel values for all lanes with respect to the original number of lanes in the original gt\n",
    "    def get_resized_gt(self, original_gt: dict, new_size = tuple):\n",
    "        seg_gt_mask = self.generate_seg_mask(original_gt)\n",
    "        \n",
    "        seg_gt_mask = Image.fromarray(np.uint8(seg_gt_mask))\n",
    "        \n",
    "        gt_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "        resized_gt_tensor = gt_transforms(seg_gt_mask)\n",
    "\n",
    "        new_gt = resized_gt_tensor.float()\n",
    "        \n",
    "        return new_gt\n",
    "              \n",
    "    # Partition dataset according to input subset size and dynamically generate the train/val splits\n",
    "    def generate_dataset(self):\n",
    "        train_set = []\n",
    "        \n",
    "        complete_idx = [idx for idx in range(0, self.complete_size)]\n",
    "        target_samples = int(self.complete_size * self.subset)\n",
    "        shuffled = random.sample(complete_idx,len(complete_idx))\n",
    "\n",
    "        # Pick n (target samples no) idx from the shuffled dataset\n",
    "        dataset_idxs = [shuffled[idx] for idx in range(0, target_samples)]\n",
    "        train_gt = [self.complete_gt[idx] for idx in dataset_idxs]\n",
    "        \n",
    "        resized_train_gt = [self.get_resized_gt(ground,self.resize) for ground in train_gt]\n",
    "        \n",
    "        # Load images, resize inputs, generate resized ground truth seg masks,transform to tensors and generate dataset (or subset)\n",
    "        for gt in train_gt:\n",
    "            img_path = gt['raw_file']\n",
    "            train_transforms = transforms.Compose([transforms.Resize(size = self.resize,interpolation=InterpolationMode.BICUBIC),\n",
    "                                                   transforms.ToTensor()\n",
    "                                                   ])\n",
    "            image = cv2.imread(os.path.join(self.train_dir, img_path))\n",
    "            image = Image.fromarray(np.uint8(image))\n",
    "            img_tensor = train_transforms(image)\n",
    "            train_set.append(img_tensor)\n",
    "        \n",
    "        return train_set, resized_train_gt   \n",
    "    \n",
    "    # Generate train and validation splits dynamically (after this operation use del dataset to free memory)\n",
    "    def train_val_split(self):\n",
    "        X = self.train_dataset\n",
    "        Y = self.train_gt\n",
    "        \n",
    "        # Split the generated train set into train and val\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size= self.val_size,random_state=42)\n",
    "        \n",
    "        train_set = BaseSplitClass(X_train, Y_train)\n",
    "        validation_set = BaseSplitClass(X_val,Y_val)\n",
    "        \n",
    "        return train_set, validation_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m TuSimple(train_annotations \u001b[39m=\u001b[39;49m annotations, train_img_dir \u001b[39m=\u001b[39;49m clips_dir, resize_to \u001b[39m=\u001b[39;49m (\u001b[39m512\u001b[39;49m,\u001b[39m512\u001b[39;49m), subset_size \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m,val_size\u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img_tns, gt \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36mTuSimple.__init__\u001b[0;34m(self, train_annotations, train_img_dir, resize_to, subset_size, image_size, val_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msf_h \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(resize_to[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m720\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_size \u001b[39m=\u001b[39m val_size\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_gt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_dataset()\n",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36mTuSimple.generate_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m dataset_idxs \u001b[39m=\u001b[39m [shuffled[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, target_samples)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m train_gt \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomplete_gt[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m dataset_idxs]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m resized_train_gt \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_resized_gt(ground,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize) \u001b[39mfor\u001b[39;00m ground \u001b[39min\u001b[39;00m train_gt]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Load images, resize inputs, generate resized ground truth seg masks,transform to tensors and generate dataset (or subset)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mfor\u001b[39;00m gt \u001b[39min\u001b[39;00m train_gt:\n",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m dataset_idxs \u001b[39m=\u001b[39m [shuffled[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, target_samples)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m train_gt \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomplete_gt[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m dataset_idxs]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m resized_train_gt \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_resized_gt(ground,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresize) \u001b[39mfor\u001b[39;00m ground \u001b[39min\u001b[39;00m train_gt]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Load images, resize inputs, generate resized ground truth seg masks,transform to tensors and generate dataset (or subset)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mfor\u001b[39;00m gt \u001b[39min\u001b[39;00m train_gt:\n",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36mTuSimple.get_resized_gt\u001b[0;34m(self, original_gt, new_size)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_resized_gt\u001b[39m(\u001b[39mself\u001b[39m, original_gt: \u001b[39mdict\u001b[39m, new_size \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     seg_gt_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_seg_mask(original_gt)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m     seg_gt_mask \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(np\u001b[39m.\u001b[39muint8(seg_gt_mask))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m     gt_transforms \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize(size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize,interpolation\u001b[39m=\u001b[39mInterpolationMode\u001b[39m.\u001b[39mBICUBIC),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m                                         transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m                                         transforms\u001b[39m.\u001b[39mGrayscale(num_output_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m                                         ])\n",
      "\u001b[1;32m/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb Cell 6\u001b[0m in \u001b[0;36mTuSimple.generate_seg_mask\u001b[0;34m(self, ground_truth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dimitris/Downloads/Lane-detection-Master-Thesis/notebooks/tusimple.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mreturn\u001b[39;00m seg_mask\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TuSimple(train_annotations = annotations, train_img_dir = clips_dir, resize_to = (512,512), subset_size = 0.001,val_size= 0.1)\n",
    "img_tns, gt = dataset[0]\n",
    "# dataset.plot_img_gt(img_tns,gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.disp_img(dataset.toImagearr(gt))\n",
    "dataset.disp_img(dataset.toImagearr(img_tns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
